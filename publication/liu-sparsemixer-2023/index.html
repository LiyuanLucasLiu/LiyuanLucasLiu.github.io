<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Liyuan Liu">

  
  
  
    
  
  <meta name="description" content="One defining characteristic of Mixture-of-Expert (MoE) models is their capacity for conducting sparse computation via expert routing, leading to remarkable scalability. However, backpropagation, the cornerstone of deep learning, requires dense computation, thereby posting challenges in MoE gradient computations. Here, we introduce SparseMixer, a scalable gradient estimator that bridges the gap between backpropagation and sparse expert routing. Unlike typical MoE training which strategically neglects certain gradient terms for the sake of sparse computation and scalability, SparseMixer provides scalable gradient approximations for these terms, enabling reliable gradient estimation in MoE training. Grounded in a numerical ODE framework, SparseMixer harnesses the mid-point method, a second-order ODE solver, to deliver precise gradient approximations with negligible computational overhead. Applying SparseMixer to Switch Transformer on both pre-training and machine translation tasks, SparseMixer showcases considerable performance gain, accelerating training convergence up to 2 times.">

  
  <link rel="alternate" hreflang="en-us" href="https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/">

  


  
  
  
  <meta name="theme-color" content="#E94A36">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_huf8c3f0a9c54db469e58ad7146e34a4a2_11050_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_huf8c3f0a9c54db469e58ad7146e34a4a2_11050_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@LiyuanLucas">
  <meta property="twitter:creator" content="@LiyuanLucas">
  
  <meta property="og:site_name" content="Liyuan Liu">
  <meta property="og:url" content="https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/">
  <meta property="og:title" content="Sparse Backpropagation for MoE Training | Liyuan Liu">
  <meta property="og:description" content="One defining characteristic of Mixture-of-Expert (MoE) models is their capacity for conducting sparse computation via expert routing, leading to remarkable scalability. However, backpropagation, the cornerstone of deep learning, requires dense computation, thereby posting challenges in MoE gradient computations. Here, we introduce SparseMixer, a scalable gradient estimator that bridges the gap between backpropagation and sparse expert routing. Unlike typical MoE training which strategically neglects certain gradient terms for the sake of sparse computation and scalability, SparseMixer provides scalable gradient approximations for these terms, enabling reliable gradient estimation in MoE training. Grounded in a numerical ODE framework, SparseMixer harnesses the mid-point method, a second-order ODE solver, to deliver precise gradient approximations with negligible computational overhead. Applying SparseMixer to Switch Transformer on both pre-training and machine translation tasks, SparseMixer showcases considerable performance gain, accelerating training convergence up to 2 times."><meta property="og:image" content="https://liyuanlucasliu.github.io/img/avatar.jpg">
  <meta property="twitter:image" content="https://liyuanlucasliu.github.io/img/avatar.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2023-10-01T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2023-10-01T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/"
  },
  "headline": "Sparse Backpropagation for MoE Training",
  
  "datePublished": "2023-10-01T00:00:00Z",
  "dateModified": "2023-10-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Liyuan Liu"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Liyuan Liu",
    "logo": {
      "@type": "ImageObject",
      "url": "https://liyuanlucasliu.github.io/images/icon_huf8c3f0a9c54db469e58ad7146e34a4a2_11050_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "One defining characteristic of Mixture-of-Expert (MoE) models is their capacity for conducting sparse computation via expert routing, leading to remarkable scalability. However, backpropagation, the cornerstone of deep learning, requires dense computation, thereby posting challenges in MoE gradient computations. Here, we introduce SparseMixer, a scalable gradient estimator that bridges the gap between backpropagation and sparse expert routing. Unlike typical MoE training which strategically neglects certain gradient terms for the sake of sparse computation and scalability, SparseMixer provides scalable gradient approximations for these terms, enabling reliable gradient estimation in MoE training. Grounded in a numerical ODE framework, SparseMixer harnesses the mid-point method, a second-order ODE solver, to deliver precise gradient approximations with negligible computational overhead. Applying SparseMixer to Switch Transformer on both pre-training and machine translation tasks, SparseMixer showcases considerable performance gain, accelerating training convergence up to 2 times."
}
</script>

  

  


  


  





  <title>Sparse Backpropagation for MoE Training | Liyuan Liu</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Liyuan Liu (Lucas)</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/"><p>Liyuan Liu</p></a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#goal"><span>Goal</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Publications</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/#publications"><span>Selected</span></a>
            
              <a class="dropdown-item" href="/publication/"><span>Full List</span></a>
            
          </div>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Honors</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/#honor"><span>Highlights</span></a>
            
              <a class="dropdown-item" href="/honor/"><span>All Honors</span></a>
            
          </div>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Activities</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/#services"><span>Services</span></a>
            
              <a class="dropdown-item" href="/experience/"><span>Experience</span></a>
            
          </div>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/blog/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/cv.pdf"><span>CV</span></a>
        </li>

        
        

      
      </ul>
    </div>





      

  </div>
</nav>


  <div class="pub">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Sparse Backpropagation for MoE Training</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    





  
    <span></span>
    <span><strong> Liyuan Liu </strong>, </span>
    <span>Jianfeng Gao, </span><span>and Weizhu Chen</span>



  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2023
  </span>
  

  

  

  
  
  

  
  



  
  <div class="share-box" aria-hidden="true">
    <ul class="share">
      
        
        
        
          
        
        
        
        <li>
          <a href="https://twitter.com/intent/tweet?url=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/&amp;text=Sparse%20Backpropagation%20for%20MoE%20Training" target="_blank" rel="noopener" class="share-btn-twitter">
            <i class="fab fa-twitter"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="https://www.facebook.com/sharer.php?u=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/&amp;t=Sparse%20Backpropagation%20for%20MoE%20Training" target="_blank" rel="noopener" class="share-btn-facebook">
            <i class="fab fa-facebook"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="mailto:?subject=Sparse%20Backpropagation%20for%20MoE%20Training&amp;body=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/" target="_blank" rel="noopener" class="share-btn-email">
            <i class="fas fa-envelope"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="https://www.linkedin.com/shareArticle?url=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/&amp;title=Sparse%20Backpropagation%20for%20MoE%20Training" target="_blank" rel="noopener" class="share-btn-linkedin">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="https://reddit.com/submit?url=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/&amp;title=Sparse%20Backpropagation%20for%20MoE%20Training" target="_blank" rel="noopener" class="share-btn-reddit">
            <i class="fab fa-reddit-alien"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="https://web.whatsapp.com/send?text=Sparse%20Backpropagation%20for%20MoE%20Training%20https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/" target="_blank" rel="noopener" class="share-btn-whatsapp">
            <i class="fab fa-whatsapp"></i>
          </a>
        </li>
      
        
        
        
          
        
        
        
        <li>
          <a href="https://service.weibo.com/share/share.php?url=https://liyuanlucasliu.github.io/publication/liu-sparsemixer-2023/&amp;title=Sparse%20Backpropagation%20for%20MoE%20Training" target="_blank" rel="noopener" class="share-btn-weibo">
            <i class="fab fa-weibo"></i>
          </a>
        </li>
      
    </ul>
  </div>
  

</div>

    











  



<div class="btn-links mb-3">
  
  








  
    
  



<a class="btn btn-outline-primary my-1 mr-1" href="https://arxiv.org/pdf/2310.00811" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 js-cite-modal"
        data-filename="/publication/liu-sparsemixer-2023/cite.bib">
  Cite
</button>















</div>


  
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">One defining characteristic of Mixture-of-Expert (MoE) models is their capacity for conducting sparse computation via expert routing, leading to remarkable scalability. However, backpropagation, the cornerstone of deep learning, requires dense computation, thereby posting challenges in MoE gradient computations. Here, we introduce SparseMixer, a scalable gradient estimator that bridges the gap between backpropagation and sparse expert routing. Unlike typical MoE training which strategically neglects certain gradient terms for the sake of sparse computation and scalability, SparseMixer provides scalable gradient approximations for these terms, enabling reliable gradient estimation in MoE training. Grounded in a numerical ODE framework, SparseMixer harnesses the mid-point method, a second-order ODE solver, to deliver precise gradient approximations with negligible computational overhead. Applying SparseMixer to Switch Transformer on both pre-training and machine translation tasks, SparseMixer showcases considerable performance gain, accelerating training convergence up to 2 times.</p>
    

    
      
      <div class="row">
        <div class="col-md-10">
          <div class="row">
            <div class="col-12 col-md-3 pub-row-heading">Type</div>
            <div class="col-12 col-md-9">
              
              
              <a href="/publication/#3">
                Preprint
              </a>
              
            </div>
          </div>
        </div>
        <div class="col-md-1"></div>
      </div>
      <div class="d-md-none space-below"></div>
      
    

    
    <div class="row">
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9"><em>arXiv:2310.00811 [cs]</em></div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>
    
    



    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/discrete-variable/">Discrete Variable</a>
  
  <a class="badge badge-light" href="/tags/moe/">MoE</a>
  
  <a class="badge badge-light" href="/tags/gradientt-estimation/">Gradientt Estimation</a>
  
  <a class="badge badge-light" href="/tags/straight-through/">Straight-Through</a>
  
  <a class="badge badge-light" href="/tags/less-tuning/">Less Tuning</a>
  
</div>


    














  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-square" src="/authors/liyuan-liu/avatar_hub04b2a45f3672cfc23ff6a0d82fcba88_258742_270x270_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://liyuanlucasliu.github.io/">Liyuan Liu</a></h5>
      <h6 class="card-subtitle">Senior Researcher @ MSR</h6>
      <p class="card-text">Understand the underlying mechanism of pretraining heuristics.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:llychinalz@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/LiyuanLucas" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/LiyuanLucasLiu" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=RmvbkzYAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/files/cv.pdf" >
        <i class="ai ai-c"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>





  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.8e8b40c0fabefe5675ec2e4754a8f5cc.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <a href="https://www.hitwebcounter.com" target="_blank">
  <img src="https://hitwebcounter.com/counter/counter.php?page=6760300&style=0006&nbdigits=8&type=page&initCount=0" title="hit counts" Alt="hit counts" style="margin-left: auto;
  margin-right: auto">
  </a>

  <p class="powered-by">
    Copyright Â© Liyuan Liu &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
